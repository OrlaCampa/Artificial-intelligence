{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YaIP_ddoUnq88qFuEk1CCo_v6x5ZPoML",
      "authorship_tag": "ABX9TyO2QaBQJYHU1V73ZqhuOAWr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OrlaCampa/Artificial-intelligence/blob/main/Text_Analysis_Tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCnBCvVTkg8N",
        "outputId": "a27f2a5f-3f67-42d3-c6a0-3efa93175a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text analysis: \n",
            "Number of words: 28\n",
            "Number of sentences: 1\n",
            "Number of paragraphs: 2\n",
            "Avarage word length: 4.89\n",
            "\n",
            "Most common words and its frequencies: \n",
            "'tigre': 6\n",
            "'leÃ³n': 4\n",
            "'vaca': 3\n",
            "'de': 2\n",
            "'mapache': 2\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "def count_words(text):\n",
        "  words = text.split()\n",
        "  return len(words)\n",
        "\n",
        "def count_sentences(text):\n",
        "  sentences = text.split('. ')\n",
        "  return len(sentences)\n",
        "\n",
        "def count_paragraphs(text):\n",
        "  paragraphs = text.split('\\n\\n')\n",
        "  return len(paragraphs)\n",
        "\n",
        "def average_word_length(text):\n",
        "  words = text.split()\n",
        "  total_length = sum(len(word) for word in words)\n",
        "  return total_length/len(words) if len(words) > 0 else 0\n",
        "\n",
        "def identify_common_words(text, top_n=5):\n",
        "  text = text.lower()\n",
        "  for sign in string.punctuation:\n",
        "    text = text.replace(sign, ' ')\n",
        "  words = text.split()\n",
        "  frequency = {}\n",
        "  for word in words:\n",
        "    frequency[word] = frequency.get(word,0) + 1\n",
        "  ordered_words = sorted(frequency.items(), key = lambda x: x[1], reverse = True)\n",
        "  return ordered_words[:top_n]\n",
        "\n",
        "file_w = '/Prueba.txt'\n",
        "\n",
        "try:\n",
        "    with open(file_w, 'r', encoding='utf-8') as fileop:\n",
        "        content = fileop.read()\n",
        "        words_num = count_words(content)\n",
        "        sentences_num = count_sentences(content)\n",
        "        paragraphs_num = count_paragraphs(content)\n",
        "        length_avr = average_word_length(content)\n",
        "        common_wrd = identify_common_words(content)\n",
        "\n",
        "        print(\"Text analysis: \")\n",
        "        print(f\"Number of words: {words_num}\")\n",
        "        print(f\"Number of sentences: {sentences_num}\")\n",
        "        print(f\"Number of paragraphs: {paragraphs_num}\")\n",
        "        print(f\"Avarage word length: {length_avr:.2f}\")\n",
        "        print(\"\\nMost common words and its frequencies: \")\n",
        "        for word, frequency in common_wrd:\n",
        "            print(f\"'{word}': {frequency}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"The file is not found in the specified path.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n"
      ]
    }
  ]
}
